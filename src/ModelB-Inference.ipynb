{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Imports\n",
    "import io\n",
    "\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datasetPath = '../Resources/KittiDataset/data_road/training/'\n",
    "testingImagesPath = pathlib.Path(datasetPath + 'bev_image_2/')\n",
    "testingLidarPath = pathlib.Path(datasetPath + 'veloImgV3/')\n",
    "outputImagesPath = pathlib.Path(datasetPath+'/allModelsResults/')\n",
    "\n",
    "modelName = \"ModelB\"\n",
    "start_time = datetime.datetime.now().strftime(\"%d_%m-%H_%M\")\n",
    "modelName = start_time + \"-\" + modelName\n",
    "\n",
    "#For tensorboard log\n",
    "base_log_dir = \"logs/\" + modelName\n",
    "file_writer = None\n",
    "tensorboard_callback = None\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "img_height = 800\n",
    "img_width = 400\n",
    "channels = 3\n",
    "fullInputChannels=6\n",
    "\n",
    "\n",
    "numClasses = 1\n",
    "seed=1234\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "#If true, only 20/10 images will be used for training/validation\n",
    "USE_SMALL_DATASET = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print a plt plot for Input, Ground Truth, Predicted mask (Predicted mask may not be neccesary)\n",
    "def display_sample(display_list, title=None):\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "    title = ['BEV Image', 'LiDAR Image', 'Predicted Mask']\n",
    "    imagesList = [display_list[0], display_list[1], display_list[2]]\n",
    "    for i in range(len(imagesList)):\n",
    "        plt.subplot(1, len(imagesList), i + 1)\n",
    "        plt.title(title[i])\n",
    "        #plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.imshow(imagesList[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#for sample_image,sample_mask in TrainingDataset.take(1):\n",
    "#    display_sample([sample_image[0][0], sample_image[1][0], sample_mask[0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_img(img_path: str) -> dict:\n",
    "  image = tf.io.read_file(img_path)\n",
    "  image = tf.io.decode_png(image, channels=channels)\n",
    "  image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "  lidarPath = tf.strings.regex_replace(img_path, \"bev_image_2\", \"veloImgV3\")\n",
    "  lidar = tf.io.read_file(lidarPath)\n",
    "  lidar = tf.io.decode_png(lidar, channels=channels)\n",
    "  lidar = tf.image.convert_image_dtype(lidar, tf.uint8)\n",
    "\n",
    "  imageFileName = tf.strings.split(img_path, \"/\")[-1]\n",
    "\n",
    "  image = tf.image.resize(image, (img_height, img_width))\n",
    "  image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "  lidar = tf.image.resize(lidar, (img_height, img_width))\n",
    "  lidar = tf.cast(lidar, tf.float32) / 255.0\n",
    "\n",
    "  inputImage = tf.concat([image, lidar], axis=2)\n",
    "\n",
    "  return (inputImage, imageFileName)\n",
    "\n",
    "\n",
    "def prepareDataset():\n",
    "    FullDataset =  tf.data.Dataset.list_files(str(testingImagesPath / '*.png'), shuffle=False)\n",
    "    FullDataset = FullDataset.map(parse_img)\n",
    "    FullDataset = FullDataset.shuffle(buffer_size=BUFFER_SIZE, seed=seed, reshuffle_each_iteration=False)\n",
    "    FullDataset = FullDataset.batch(BATCH_SIZE)\n",
    "    FullDataset = FullDataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return FullDataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepareModel():\n",
    "    #Encoder1\n",
    "    input1 = tf.keras.Input(shape=(img_height,img_width,fullInputChannels), name='inputLayer_1')\n",
    "\n",
    "    e1_c1_1 = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv1_1\")(input1)\n",
    "    e1_c1_2 = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv1_2\")(e1_c1_1)\n",
    "    e1_pool1 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same', name=\"e1_pool1\")(e1_c1_2)\n",
    "\n",
    "    e1_c2_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv2_1\")(e1_pool1)\n",
    "    e1_c2_2 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv2_2\")(e1_c2_1)\n",
    "    e1_pool2 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same', name=\"e1_pool2\")(e1_c2_2)\n",
    "\n",
    "    e1_c3_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv3_1\")(e1_pool2)\n",
    "    e1_c3_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv3_2\")(e1_c3_1)\n",
    "    e1_c3_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv3_3\")(e1_c3_2)\n",
    "    e1_pool3 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same', name=\"e1_pool3\")(e1_c3_3)\n",
    "\n",
    "    e1_c4_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv4_1\")(e1_pool3)\n",
    "    e1_c4_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv4_2\")(e1_c4_1)\n",
    "    e1_c4_3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv4_3\")(e1_c4_2)\n",
    "    e1_pool4 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same', name=\"e1_pool4\")(e1_c4_3)\n",
    "\n",
    "    e1 = tf.keras.models.Model(inputs=[input1], outputs=e1_pool4, name=\"Encoder1\")\n",
    "\n",
    "    fc6 = tf.keras.layers.Dense(units=1024, name='fc6')(e1.output)\n",
    "    drop6 = tf.keras.layers.Dropout(rate=DROPOUT_RATE, name='drop6')(fc6)\n",
    "\n",
    "    fc7 = tf.keras.layers.Dense(units=1024, name='fc7')(drop6)\n",
    "    drop7 = tf.keras.layers.Dropout(rate=DROPOUT_RATE, name='e2_drop7')(fc7)\n",
    "\n",
    "    dc10 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=16, strides=(2,2), padding='same', name='dconv10')(drop7)\n",
    "\n",
    "    c10_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', name=\"conv10_1\")(dc10)\n",
    "    c10_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', name=\"conv10_2\")(c10_1)\n",
    "    c10_3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', name=\"conv10_3\")(c10_2)\n",
    "\n",
    "    dc11 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=16, strides=(2,2), padding='same', name='dconv11')(c10_3)\n",
    "\n",
    "    c11_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', name=\"conv11_1\")(dc11)\n",
    "    c11_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', name=\"conv11_2\")(c11_1)\n",
    "    c11_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', name=\"conv11_3\")(c11_2)\n",
    "\n",
    "    dc12 = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=16, strides=(2,2), padding='same', name='dconv12')(c11_3)\n",
    "\n",
    "    c12_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', name=\"conv12_1\")(dc12)\n",
    "    c12_2 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', name=\"conv12_2\")(c12_1)\n",
    "\n",
    "    dc13 = tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=16, strides=(2,2), padding='same', name='dconv13')(c12_2)\n",
    "    c13_1 = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu', name=\"conv13_1\")(dc13)\n",
    "    c13_2 = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu', name=\"conv13_2\")(c13_1)\n",
    "\n",
    "    outputLayer = tf.keras.layers.Conv2D(filters=numClasses, kernel_size=16, strides=(1,1), padding='same', activation='sigmoid', name=\"output_layer\")(c13_2)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[e1.inputs], outputs=[outputLayer])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = prepareModel()\n",
    "#model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['mse', tf.keras.metrics.BinaryIoU(target_class_ids=[1], name='BinaryIoU')], run_eagerly=False)\n",
    "\n",
    "model.load_weights('Models/ModelB.h5')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "i=0\n",
    "timeList = []\n",
    "\n",
    "FullDataset = prepareDataset()\n",
    "\n",
    "#for image,filePath in FullDataset:\n",
    "for image,filePath in FullDataset.take(10):\n",
    "    fileName = filePath[0].numpy().decode('utf-8').split(\"\\\\\")[-1]\n",
    "    splittedFileName = fileName.split('_')\n",
    "    type = splittedFileName[0]\n",
    "    imageNumber = splittedFileName[1].split('.')[0]\n",
    "\n",
    "    outputFileName = type + '_road_' + imageNumber + '.png'\n",
    "    outputPath = str(outputImagesPath) + '/B--' + outputFileName\n",
    "\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    predMask = model.predict(image)[0]\n",
    "\n",
    "\n",
    "    end = time.time()\n",
    "    elapsed = end-start\n",
    "    timeList.append(elapsed)\n",
    "\n",
    "    #print(elapsed)\n",
    "\n",
    "    predMask = tf.image.resize(predMask, (800, 400))\n",
    "\n",
    "    invertedMask = np.ones((800,400,1)) - predMask\n",
    "\n",
    "    splittedImage = tf.split(image[0], 2, axis=2)\n",
    "\n",
    "    #display_sample([splittedImage[0], splittedImage[1], predMask])\n",
    "\n",
    "    tf.keras.utils.save_img(outputPath, predMask, scale=True)\n",
    "    #print(i)\n",
    "    i+=1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Mean prediction time:\")\n",
    "print(np.mean(timeList))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
