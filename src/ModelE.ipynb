{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Imports\n",
    "import io\n",
    "\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "datasetPath = '../Resources/KittiDataset/data_road/training/'\n",
    "trainingImagesPath = pathlib.Path(datasetPath+'bev_image_2/')\n",
    "trainingGTPath = pathlib.Path(datasetPath+'bev_gt_image_2/')\n",
    "trainingLidarPath = pathlib.Path(datasetPath+'bev_velodyne/')\n",
    "\n",
    "modelName = \"ModelE\"\n",
    "time = datetime.datetime.now().strftime(\"%d_%m-%H_%M\")\n",
    "modelName = time+\"-\"+modelName\n",
    "\n",
    "#For tensorboard log\n",
    "base_log_dir = \"logs/\" + modelName\n",
    "file_writer = None\n",
    "tensorboard_callback = None\n",
    "\n",
    "\n",
    "\n",
    "BUFFER_SIZE = 1000\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 0.0001\n",
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "img_height = 800\n",
    "img_width = 400\n",
    "channels = 3\n",
    "\n",
    "\n",
    "numClasses = 1\n",
    "seed=1234\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "AUGMENT = False\n",
    "AUGMENT_RATE = 1\n",
    "\n",
    "#If true, only 20/10 images will be used for training/validation\n",
    "USE_SMALL_DATASET = True"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Print a plt plot for Input, Ground Truth, Predicted mask (Predicted mask may not be neccesary)\n",
    "def display_sample(display_list, title=None):\n",
    "    fig = plt.figure(figsize=(5, 5))\n",
    "    if title is not None:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "    title = ['BEV Image', 'True Mask', 'Predicted Mask']\n",
    "    imagesList = [display_list[0], display_list[1], display_list[2]]\n",
    "    if len(display_list) == 4:\n",
    "        imagesList.append(display_list[3])\n",
    "    for i in range(len(imagesList)):\n",
    "        plt.subplot(1, len(imagesList), i + 1)\n",
    "        plt.title(title[i])\n",
    "        #plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.imshow(imagesList[i])\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "#for sample_image,sample_mask in TrainingDataset.take(1):\n",
    "#    display_sample([sample_image[0][0], sample_image[1][0], sample_mask[0]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def parse_img(img_path: str) -> dict:\n",
    "  image = tf.io.read_file(img_path)\n",
    "  image = tf.io.decode_png(image, channels=channels)\n",
    "  image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "  imageFileName = tf.strings.split(img_path, \"/\")[-1]\n",
    "  splitedFileName = tf.strings.split(imageFileName, \"_\")\n",
    "\n",
    "  imageType = splitedFileName[0]\n",
    "  imageNumber = tf.strings.split(splitedFileName[1], \".\")[0]\n",
    "\n",
    "  maskFileName = imageType + \"_road_\" + imageNumber + \".png\"\n",
    "\n",
    "  mask_path = tf.strings.regex_replace(img_path, \"bev_image_2\", \"bev_gt_image_2\")\n",
    "  mask_path = tf.strings.regex_replace(mask_path, imageFileName, maskFileName)\n",
    "\n",
    "  maskImage = tf.io.read_file(mask_path)\n",
    "  maskImage = tf.io.decode_png(maskImage, channels=channels)\n",
    "\n",
    "  splittedMaskImage = tf.split(maskImage, 3, axis=2)\n",
    "  maskImage = splittedMaskImage[2]\n",
    "\n",
    "  image = tf.image.resize(image, (img_height, img_width))\n",
    "  image = tf.cast(image, tf.float32) / 255.0\n",
    "\n",
    "  maskImage = tf.image.resize(maskImage, (img_height, img_width)) /255\n",
    "  maskImage = tf.cast(maskImage, tf.int8)\n",
    "\n",
    "\n",
    "\n",
    "  return (image, maskImage)\n",
    "\n",
    "def augment(data):\n",
    "    img, mask = data\n",
    "\n",
    "    img = img[0]\n",
    "    mask = mask[0]\n",
    "\n",
    "    #Flip left/right\n",
    "    img = tf.image.flip_left_right(img)\n",
    "    mask = tf.image.flip_left_right(mask)\n",
    "\n",
    "    img = img[tf.newaxis, ...]\n",
    "    mask = mask[tf.newaxis, ...]\n",
    "\n",
    "    return img, mask\n",
    "\n",
    "# Create a wrapper function for updating seeds.\n",
    "def augmentingFunction(x, y):\n",
    "    image, label = augment((x, y))\n",
    "    return image, label\n",
    "\n",
    "def augmentDataset(inputDataset):\n",
    "    #print('Training dataset size before augmentation: ' + str(inputDataset.cardinality().numpy()))\n",
    "    AugmentedDataset = inputDataset.take(round(inputDataset.cardinality().numpy() * AUGMENT_RATE))\n",
    "    AugmentedDataset = AugmentedDataset.map(augmentingFunction)\n",
    "\n",
    "    inputDataset = inputDataset.concatenate(AugmentedDataset)\n",
    "    #print('Training dataset size after augmentation: ' + str(inputDataset.cardinality().numpy()))\n",
    "\n",
    "    return inputDataset\n",
    "\n",
    "def prepareDatasetKFolds(nFolds=10):\n",
    "    FullDatasetSize = len(list(trainingImagesPath.glob('*.png')))\n",
    "    foldSize = int(FullDatasetSize / nFolds)\n",
    "\n",
    "    FullDataset =  tf.data.Dataset.list_files(str(trainingImagesPath/'*.png'), shuffle=False)\n",
    "    FullDataset = FullDataset.map(parse_img)\n",
    "    FullDataset = FullDataset.shuffle(buffer_size=BUFFER_SIZE, seed=seed, reshuffle_each_iteration=False)\n",
    "\n",
    "    folds = []\n",
    "    trainingSplits = []\n",
    "    validationSplits = []\n",
    "\n",
    "    for i in range(nFolds-1):\n",
    "        folds.append(FullDataset.skip(foldSize*i).take(foldSize))\n",
    "\n",
    "    skipped = foldSize*(nFolds-1)\n",
    "    folds.append(FullDataset.skip(foldSize*(nFolds-1)))\n",
    "\n",
    "    for i in range(nFolds):\n",
    "        trainingFolds = folds[:i]\n",
    "        trainingFolds.extend(folds[(i+1):])\n",
    "\n",
    "        trainingSplit = FullDataset.take(0)\n",
    "        for fold in trainingFolds:\n",
    "            trainingSplit = trainingSplit.concatenate(fold)\n",
    "\n",
    "        validationSplit = folds[i]\n",
    "\n",
    "        trainingSplit = trainingSplit.batch(BATCH_SIZE)\n",
    "        trainingSplit = trainingSplit.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "        validationSplit = validationSplit.batch(BATCH_SIZE)\n",
    "        validationSplit = validationSplit.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "        trainingSplit = augmentDataset(trainingSplit)\n",
    "\n",
    "        trainingSplits.append(trainingSplit)\n",
    "        validationSplits.append(validationSplit)\n",
    "\n",
    "\n",
    "    return trainingSplits, validationSplits"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prepareModel():\n",
    "    #Encoder1\n",
    "    input1 = tf.keras.Input(shape=(img_height,img_width,channels), name='inputLayer_1')\n",
    "\n",
    "    e1_c1_1 = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv1_1\")(input1)\n",
    "    e1_c1_2 = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv1_2\")(e1_c1_1)\n",
    "    e1_pool1 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same', name=\"e1_pool1\")(e1_c1_2)\n",
    "\n",
    "    e1_c2_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv2_1\")(e1_pool1)\n",
    "    e1_c2_2 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv2_2\")(e1_c2_1)\n",
    "    e1_pool2 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same', name=\"e1_pool2\")(e1_c2_2)\n",
    "\n",
    "    e1_c3_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv3_1\")(e1_pool2)\n",
    "    e1_c3_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv3_2\")(e1_c3_1)\n",
    "    e1_c3_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv3_3\")(e1_c3_2)\n",
    "    e1_pool3 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same', name=\"e1_pool3\")(e1_c3_3)\n",
    "\n",
    "    e1_c4_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv4_1\")(e1_pool3)\n",
    "    e1_c4_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv4_2\")(e1_c4_1)\n",
    "    e1_c4_3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', name=\"e1_conv4_3\")(e1_c4_2)\n",
    "    e1_pool4 = tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2), padding='same', name=\"e1_pool4\")(e1_c4_3)\n",
    "\n",
    "    e1 = tf.keras.models.Model(inputs=[input1], outputs=e1_pool4, name=\"Encoder1\")\n",
    "\n",
    "    fc6 = tf.keras.layers.Dense(units=1024, name='fc6')(e1.output)\n",
    "    drop6 = tf.keras.layers.Dropout(rate=DROPOUT_RATE, name='drop6')(fc6)\n",
    "\n",
    "    fc7 = tf.keras.layers.Dense(units=1024, name='fc7')(drop6)\n",
    "    drop7 = tf.keras.layers.Dropout(rate=DROPOUT_RATE, name='e2_drop7')(fc7)\n",
    "\n",
    "    dc10 = tf.keras.layers.Conv2DTranspose(filters=128, kernel_size=16, strides=(2,2), padding='same', name='dconv10')(drop7)\n",
    "\n",
    "    agX = tf.keras.layers.Add(name=\"agX\")([dc10, e1_c4_3])\n",
    "\n",
    "    c10_1 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', name=\"conv10_1\")(agX)\n",
    "    c10_2 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', name=\"conv10_2\")(c10_1)\n",
    "    c10_3 = tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation='relu', name=\"conv10_3\")(c10_2)\n",
    "\n",
    "    dc11 = tf.keras.layers.Conv2DTranspose(filters=64, kernel_size=16, strides=(2,2), padding='same', name='dconv11')(c10_3)\n",
    "\n",
    "    agY = tf.keras.layers.Add(name=\"agY\")([dc11, e1_c3_3])\n",
    "\n",
    "    c11_1 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', name=\"conv11_1\")(agY)\n",
    "    c11_2 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', name=\"conv11_2\")(c11_1)\n",
    "    c11_3 = tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation='relu', name=\"conv11_3\")(c11_2)\n",
    "\n",
    "    dc12 = tf.keras.layers.Conv2DTranspose(filters=32, kernel_size=16, strides=(2,2), padding='same', name='dconv12')(c11_3)\n",
    "\n",
    "    agZ = tf.keras.layers.Add(name=\"agZ\")([dc12, e1_c2_2])\n",
    "\n",
    "    c12_1 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', name=\"conv12_1\")(agZ)\n",
    "    c12_2 = tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation='relu', name=\"conv12_2\")(c12_1)\n",
    "\n",
    "    dc13 = tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=16, strides=(2,2), padding='same', name='dconv13')(c12_2)\n",
    "    c13_1 = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu', name=\"conv13_1\")(dc13)\n",
    "    c13_2 = tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding='same', activation='relu', name=\"conv13_2\")(c13_1)\n",
    "\n",
    "    outputLayer = tf.keras.layers.Conv2D(filters=numClasses, kernel_size=16, strides=(1,1), padding='same', activation='sigmoid', name=\"output_layer\")(c13_2)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=[e1.inputs], outputs=[outputLayer])\n",
    "\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = prepareModel()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sample_image, sample_mask = None, None\n",
    "\n",
    "def imageToTensorboard(epoch):\n",
    "    global sample_image\n",
    "    global sample_mask\n",
    "    img = sample_image[0]\n",
    "    mask = sample_mask[0]\n",
    "\n",
    "    #Predict mask\n",
    "    #one_img_batch = sample_image\n",
    "    pred_mask = model.predict(sample_image)[0]\n",
    "    display_list = [img, mask, pred_mask]\n",
    "\n",
    "    #Create plot\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    title = ['Camera', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.title(title[i])\n",
    "        plt.imshow(display_list[i])\n",
    "        plt.axis('off')\n",
    "\n",
    "    #Convert plot to png image\n",
    "    buf = io.BytesIO()\n",
    "    plt.savefig(buf, format='png')\n",
    "    plt.close(fig)\n",
    "    buf.seek(0)\n",
    "    img = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    img = tf.expand_dims(img, 0)\n",
    "\n",
    "    with file_writer.as_default():\n",
    "        tf.summary.image(\"Training\", img, step=epoch+1)\n",
    "\n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        imageToTensorboard(epoch=epoch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(TrainingDataset, ValidationDataset, foldNumber):\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE), loss=tf.keras.losses.BinaryCrossentropy(), metrics=['mse', tf.keras.metrics.BinaryIoU(target_class_ids=[1], name='BinaryIoU')], run_eagerly=False)\n",
    "\n",
    "    stepsPerEpoch = TrainingDataset.cardinality().numpy() // BATCH_SIZE\n",
    "    validationSteps = ValidationDataset.cardinality().numpy() // BATCH_SIZE\n",
    "\n",
    "    global sample_data\n",
    "    sample_data = ValidationDataset.take(1)\n",
    "\n",
    "\n",
    "    callbacks = [\n",
    "                 tensorboard_callback,\n",
    "                 DisplayCallback(),\n",
    "                 tf.keras.callbacks.ModelCheckpoint(\"./Models/\"+modelName+\"_Fold-\"+str(foldNumber)+\".h5\", verbose=1, save_best_only=True),\n",
    "                 tf.keras.callbacks.EarlyStopping(patience=10, verbose=1)\n",
    "                 ]\n",
    "\n",
    "    model_history = model.fit(TrainingDataset,\n",
    "                          epochs=50,\n",
    "                          validation_steps=validationSteps,\n",
    "                          validation_data=ValidationDataset,\n",
    "                          callbacks=callbacks)\n",
    "\n",
    "    return model_history"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "K = 10\n",
    "\n",
    "trainingSplits, validationSplits = prepareDatasetKFolds(K)\n",
    "for i, m in trainingSplits[0].take(1):\n",
    "    sample_image = i\n",
    "    sample_mask = m\n",
    "\n",
    "model_history = None\n",
    "\n",
    "val_binaryIoU_list = []\n",
    "\n",
    "for trainSplit, validationSplit, i in zip(trainingSplits, validationSplits, list(range(K))):\n",
    "    global model\n",
    "    global file_writer\n",
    "    global tensorboard_callback\n",
    "\n",
    "    model = prepareModel()\n",
    "    log_dir = base_log_dir + \"/Fold_\"+str(i)\n",
    "    file_writer = tf.summary.create_file_writer(log_dir)\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "    print(\"Starting fold: \" + str(i))\n",
    "    model_history = train(trainSplit, validationSplit, i)\n",
    "    val_binaryIoU = model_history.history['val_BinaryIoU'][-1]\n",
    "    val_binaryIoU_list.append(val_binaryIoU)\n",
    "    print(\"Ending fold: \" + str(i))\n",
    "    print(\"Validation BinaryIoU for fold \" + str(i) + \": \" + str(val_binaryIoU))\n",
    "    print(\"#############################################################################3\")\n",
    "\n",
    "mean_val_binaryIoU = sum(val_binaryIoU_list) / len(val_binaryIoU_list)\n",
    "\n",
    "with tf.summary.create_file_writer(base_log_dir).as_default():\n",
    "    tf.summary.scalar('Mean_val_BinaryIoU', mean_val_binaryIoU, step=1)\n",
    "\n",
    "print(\"Mean val BinaryIoU: \"+str(mean_val_binaryIoU))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Done\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
